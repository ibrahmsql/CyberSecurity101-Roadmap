#!/usr/bin/env python3
"""
Malware Analysis Toolkit
Comprehensive malware analysis tools for static, dynamic, and behavioral analysis
"""

import os
import subprocess
import json
import hashlib
import time
import math
import re
import struct
from datetime import datetime
from collections import Counter
from threading import Thread
import psutil
import pefile
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib

class StaticAnalyzer:
    """Static malware analysis toolkit"""
    
    def __init__(self, file_path):
        self.file_path = file_path
        self.pe = None
        self.analysis_results = {}
        
        # Try to load as PE file
        try:
            self.pe = pefile.PE(file_path)
        except:
            pass
    
    def get_basic_info(self):
        """Extract basic file information"""
        with open(self.file_path, 'rb') as f:
            data = f.read()
        
        file_info = {
            'file_size': len(data),
            'md5': hashlib.md5(data).hexdigest(),
            'sha1': hashlib.sha1(data).hexdigest(),
            'sha256': hashlib.sha256(data).hexdigest()
        }
        
        # Calculate ssdeep if available
        try:
            import ssdeep
            file_info['ssdeep'] = ssdeep.hash(data)
        except ImportError:
            file_info['ssdeep'] = 'ssdeep not available'
        
        return file_info
    
    def analyze_pe_structure(self):
        """Analyze PE file structure"""
        if not self.pe:
            return {'error': 'Not a valid PE file'}
        
        pe_info = {
            'machine': hex(self.pe.FILE_HEADER.Machine),
            'timestamp': self.pe.FILE_HEADER.TimeDateStamp,
            'sections': len(self.pe.sections),
            'entry_point': hex(self.pe.OPTIONAL_HEADER.AddressOfEntryPoint),
            'image_base': hex(self.pe.OPTIONAL_HEADER.ImageBase)
        }
        
        # Section details
        sections = []
        for section in self.pe.sections:
            section_info = {
                'name': section.Name.decode().rstrip('\x00'),
                'virtual_address': hex(section.VirtualAddress),
                'virtual_size': section.Misc_VirtualSize,
                'raw_size': section.SizeOfRawData,
                'entropy': section.get_entropy()
            }
            sections.append(section_info)
        
        pe_info['section_details'] = sections
        
        # Import analysis
        imports = []
        if hasattr(self.pe, 'DIRECTORY_ENTRY_IMPORT'):
            for entry in self.pe.DIRECTORY_ENTRY_IMPORT:
                dll_info = {
                    'dll': entry.dll.decode(),
                    'functions': []
                }
                
                for imp in entry.imports:
                    if imp.name:
                        dll_info['functions'].append(imp.name.decode())
                
                imports.append(dll_info)
        
        pe_info['imports'] = imports
        
        return pe_info
    
    def extract_strings(self, min_length=4):
        """Extract strings from file"""
        with open(self.file_path, 'rb') as f:
            data = f.read()
        
        # ASCII strings
        ascii_strings = re.findall(rb'[\x20-\x7E]{' + str(min_length).encode() + rb',}', data)
        
        # Unicode strings
        unicode_strings = re.findall(rb'(?:[\x20-\x7E]\x00){' + str(min_length).encode() + rb',}', data)
        
        # Count interesting patterns
        all_strings = b' '.join(ascii_strings + unicode_strings)
        
        interesting_patterns = {
            'urls': len(re.findall(rb'https?://', all_strings)),
            'ips': len(re.findall(rb'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', all_strings)),
            'emails': len(re.findall(rb'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', all_strings)),
            'registry_keys': len(re.findall(rb'HKEY_', all_strings))
        }
        
        return {
            'ascii_count': len(ascii_strings),
            'unicode_count': len(unicode_strings),
            'interesting_patterns': interesting_patterns
        }

class DynamicAnalyzer:
    """Dynamic malware analysis with process monitoring"""
    
    def __init__(self, malware_path, analysis_duration=300):
        self.malware_path = malware_path
        self.analysis_duration = analysis_duration
        self.monitoring_data = {
            'process_activity': [],
            'file_operations': [],
            'network_connections': [],
            'registry_changes': [],
            'system_changes': []
        }
        self.baseline_processes = set()
        self.baseline_files = set()
        self.monitoring = False
        
    def take_baseline(self):
        """Take system baseline before execution"""
        # Baseline processes
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                self.baseline_processes.add(proc.info['name'])
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # Baseline files (sample directory)
        sample_dirs = ['/tmp', '/var/tmp']
        for directory in sample_dirs:
            if os.path.exists(directory):
                for root, dirs, files in os.walk(directory):
                    for file in files:
                        self.baseline_files.add(os.path.join(root, file))
    
    def monitor_processes(self):
        """Monitor process creation and termination"""
        while self.monitoring:
            current_processes = set()
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):
                try:
                    proc_info = proc.info
                    current_processes.add(proc_info['name'])
                    
                    # New process detected
                    if proc_info['name'] not in self.baseline_processes:
                        self.monitoring_data['process_activity'].append({
                            'timestamp': time.time(),
                            'action': 'created',
                            'pid': proc_info['pid'],
                            'name': proc_info['name'],
                            'cmdline': proc_info['cmdline'],
                            'create_time': proc_info['create_time']
                        })
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            # Check for terminated processes
            for proc_name in self.baseline_processes:
                if proc_name not in current_processes:
                    self.monitoring_data['process_activity'].append({
                        'timestamp': time.time(),
                        'action': 'terminated',
                        'name': proc_name
                    })
            
            self.baseline_processes = current_processes
            time.sleep(1)
    
    def monitor_network(self):
        """Monitor network connections"""
        baseline_connections = set()
        
        # Get baseline connections
        for conn in psutil.net_connections():
            if conn.status == 'ESTABLISHED':
                baseline_connections.add((conn.laddr, conn.raddr))
        
        while self.monitoring:
            current_connections = set()
            for conn in psutil.net_connections():
                try:
                    if conn.status == 'ESTABLISHED':
                        conn_tuple = (conn.laddr, conn.raddr)
                        current_connections.add(conn_tuple)
                        
                        # New connection detected
                        if conn_tuple not in baseline_connections:
                            self.monitoring_data['network_connections'].append({
                                'timestamp': time.time(),
                                'local_addr': conn.laddr,
                                'remote_addr': conn.raddr,
                                'status': conn.status,
                                'pid': conn.pid
                            })
                            
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            baseline_connections = current_connections
            time.sleep(2)

class AdvancedMalwareAnalyzer:
    """Advanced malware analysis toolkit"""
    
    def __init__(self, sample_path, memory_dump=None):
        self.sample_path = sample_path
        self.memory_dump = memory_dump
        self.analysis_results = {
            'timestamp': datetime.now().isoformat(),
            'sample_path': sample_path,
            'static_analysis': {},
            'dynamic_analysis': {},
            'memory_analysis': {},
            'network_analysis': {},
            'behavioral_analysis': {}
        }
    
    def static_analysis(self):
        """Comprehensive static analysis"""
        print("[+] Starting static analysis...")
        
        # File type detection
        try:
            file_type = subprocess.run(
                ['file', self.sample_path],
                capture_output=True, text=True
            ).stdout.strip()
        except:
            file_type = 'Unknown'
        
        self.analysis_results['static_analysis']['file_type'] = file_type
        
        # Entropy analysis
        entropy_result = self.calculate_entropy()
        self.analysis_results['static_analysis']['entropy'] = entropy_result
        
        # String extraction
        strings_result = self.extract_strings()
        self.analysis_results['static_analysis']['strings'] = strings_result
        
        # PE analysis (if applicable)
        if 'PE32' in file_type or self.sample_path.endswith('.exe'):
            pe_result = self.analyze_pe_structure()
            self.analysis_results['static_analysis']['pe_analysis'] = pe_result
        
        return self.analysis_results['static_analysis']
    
    def calculate_entropy(self):
        """Calculate file entropy"""
        with open(self.sample_path, 'rb') as f:
            data = f.read()
        
        # Calculate byte frequency
        byte_counts = Counter(data)
        file_size = len(data)
        
        # Calculate entropy
        entropy = 0
        for count in byte_counts.values():
            probability = count / file_size
            entropy -= probability * math.log2(probability)
        
        return {
            'entropy': entropy,
            'assessment': 'High' if entropy > 7.0 else 'Normal',
            'packed_likelihood': 'High' if entropy > 7.5 else 'Low'
        }
    
    def extract_strings(self, min_length=4):
        """Extract ASCII and Unicode strings"""
        with open(self.sample_path, 'rb') as f:
            data = f.read()
        
        # ASCII strings
        ascii_strings = re.findall(rb'[\x20-\x7E]{' + str(min_length).encode() + rb',}', data)
        
        # Unicode strings
        unicode_strings = re.findall(rb'(?:[\x20-\x7E]\x00){' + str(min_length).encode() + rb',}', data)
        
        # Interesting patterns
        interesting = {
            'urls': re.findall(rb'https?://[\x20-\x7E]+', data),
            'ips': re.findall(rb'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', data),
            'emails': re.findall(rb'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', data),
            'file_paths': re.findall(rb'[A-Za-z]:\\\\[\x20-\x7E\\\\]+', data),
            'registry_keys': re.findall(rb'HKEY_[A-Z_]+\\\\[\x20-\x7E\\\\]+', data)
        }
        
        return {
            'ascii_count': len(ascii_strings),
            'unicode_count': len(unicode_strings),
            'interesting_patterns': {k: [s.decode('utf-8', errors='ignore') for s in v] for k, v in interesting.items()}
        }
    
    def analyze_pe_structure(self):
        """Detailed PE structure analysis"""
        try:
            pe = pefile.PE(self.sample_path)
            
            # Basic PE info
            pe_info = {
                'machine_type': hex(pe.FILE_HEADER.Machine),
                'timestamp': pe.FILE_HEADER.TimeDateStamp,
                'entry_point': hex(pe.OPTIONAL_HEADER.AddressOfEntryPoint),
                'image_base': hex(pe.OPTIONAL_HEADER.ImageBase),
                'section_count': len(pe.sections)
            }
            
            # Section analysis
            sections = []
            for section in pe.sections:
                section_info = {
                    'name': section.Name.decode().rstrip('\x00'),
                    'virtual_address': hex(section.VirtualAddress),
                    'virtual_size': section.Misc_VirtualSize,
                    'raw_size': section.SizeOfRawData,
                    'entropy': section.get_entropy(),
                    'characteristics': hex(section.Characteristics)
                }
                
                # Suspicious characteristics
                if section.get_entropy() > 7.0:
                    section_info['suspicious'] = 'High entropy - possibly packed'
                
                if section.Characteristics & 0x20000000:  # IMAGE_SCN_MEM_EXECUTE
                    if section.Characteristics & 0x80000000:  # IMAGE_SCN_MEM_WRITE
                        section_info['suspicious'] = 'Executable and writable'
                
                sections.append(section_info)
            
            pe_info['sections'] = sections
            
            # Import analysis
            imports = []
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    dll_info = {
                        'dll': entry.dll.decode(),
                        'functions': []
                    }
                    
                    for imp in entry.imports:
                        if imp.name:
                            dll_info['functions'].append(imp.name.decode())
                    
                    imports.append(dll_info)
            
            pe_info['imports'] = imports
            
            # Suspicious API detection
            suspicious_apis = [
                'CreateProcess', 'WriteProcessMemory', 'VirtualAlloc',
                'SetWindowsHook', 'RegSetValue', 'CreateService',
                'InternetOpen', 'HttpSendRequest', 'CryptEncrypt'
            ]
            
            found_suspicious = []
            for dll_info in imports:
                for func in dll_info['functions']:
                    if any(api in func for api in suspicious_apis):
                        found_suspicious.append(f"{dll_info['dll']}:{func}")
            
            pe_info['suspicious_apis'] = found_suspicious
            
            return pe_info
            
        except Exception as e:
            return {'error': str(e)}
    
    def behavioral_analysis(self):
        """Analyze malware behavior patterns"""
        print("[+] Starting behavioral analysis...")
        
        # Behavioral indicators based on static analysis
        behaviors = []
        
        # Check for persistence mechanisms
        static_results = self.analysis_results.get('static_analysis', {})
        strings = static_results.get('strings', {}).get('interesting_patterns', {})
        
        if strings.get('registry_keys'):
            behaviors.append({
                'category': 'Persistence',
                'description': 'Registry modification detected',
                'evidence': strings['registry_keys'][:5]  # First 5 entries
            })
        
        if strings.get('file_paths'):
            behaviors.append({
                'category': 'File System',
                'description': 'File system access detected',
                'evidence': strings['file_paths'][:5]
            })
        
        if strings.get('urls') or strings.get('ips'):
            behaviors.append({
                'category': 'Network Communication',
                'description': 'Network communication capability detected',
                'evidence': (strings.get('urls', []) + strings.get('ips', []))[:5]
            })
        
        # Check for suspicious APIs
        pe_analysis = static_results.get('pe_analysis', {})
        if pe_analysis.get('suspicious_apis'):
            behaviors.append({
                'category': 'Suspicious API Usage',
                'description': 'Potentially malicious API calls detected',
                'evidence': pe_analysis['suspicious_apis'][:10]
            })
        
        return behaviors
    
    def calculate_risk_score(self):
        """Calculate overall risk score"""
        score = 0
        factors = []
        
        static_analysis = self.analysis_results.get('static_analysis', {})
        
        # High entropy
        entropy = static_analysis.get('entropy', {})
        if entropy.get('entropy', 0) > 7.0:
            score += 30
            factors.append('High entropy (possibly packed)')
        
        # Suspicious APIs
        pe_analysis = static_analysis.get('pe_analysis', {})
        suspicious_apis = pe_analysis.get('suspicious_apis', [])
        if suspicious_apis:
            score += len(suspicious_apis) * 5
            factors.append(f'{len(suspicious_apis)} suspicious API calls')
        
        # Network indicators
        strings = static_analysis.get('strings', {}).get('interesting_patterns', {})
        network_indicators = len(strings.get('urls', [])) + len(strings.get('ips', []))
        if network_indicators > 0:
            score += network_indicators * 10
            factors.append(f'{network_indicators} network indicators')
        
        # Determine risk level
        if score >= 80:
            risk_level = 'Critical'
        elif score >= 60:
            risk_level = 'High'
        elif score >= 40:
            risk_level = 'Medium'
        elif score >= 20:
            risk_level = 'Low'
        else:
            risk_level = 'Minimal'
        
        return {
            'score': score,
            'level': risk_level,
            'factors': factors
        }
    
    def generate_comprehensive_report(self):
        """Generate comprehensive analysis report"""
        print("[+] Generating comprehensive malware analysis report...")
        
        # Run all analysis modules
        self.static_analysis()
        
        # Behavioral analysis
        self.analysis_results['behavioral_analysis'] = self.behavioral_analysis()
        
        # Risk assessment
        risk_score = self.calculate_risk_score()
        self.analysis_results['risk_assessment'] = risk_score
        
        # Recommendations
        recommendations = self.generate_recommendations()
        self.analysis_results['recommendations'] = recommendations
        
        return self.analysis_results
    
    def generate_recommendations(self):
        """Generate security recommendations"""
        recommendations = []
        
        risk_assessment = self.analysis_results.get('risk_assessment', {})
        risk_level = risk_assessment.get('level', 'Unknown')
        
        if risk_level in ['Critical', 'High']:
            recommendations.extend([
                'Immediately isolate affected systems',
                'Run full antivirus scan on all systems',
                'Check for lateral movement indicators',
                'Review network logs for C&C communication',
                'Consider incident response procedures'
            ])
        
        elif risk_level == 'Medium':
            recommendations.extend([
                'Monitor system for suspicious activity',
                'Update antivirus signatures',
                'Review system logs',
                'Consider additional analysis'
            ])
        
        else:
            recommendations.extend([
                'Continue monitoring',
                'Maintain current security posture',
                'Regular security updates'
            ])
        
        # Specific recommendations based on findings
        static_analysis = self.analysis_results.get('static_analysis', {})
        
        if static_analysis.get('entropy', {}).get('entropy', 0) > 7.0:
            recommendations.append('Consider unpacking analysis for packed malware')
        
        return recommendations
    
    def save_report(self, output_file):
        """Save analysis report to file"""
        with open(output_file, 'w') as f:
            json.dump(self.analysis_results, f, indent=2, default=str)
        
        print(f"[+] Report saved to: {output_file}")

class PackedMalwareAnalyzer:
    """Packed malware analysis toolkit"""
    
    def __init__(self, packed_file):
        self.packed_file = packed_file
        self.pe = pefile.PE(packed_file)
        
    def detect_packer(self):
        """Detect common packers"""
        packer_signatures = {
            'UPX': [b'UPX0', b'UPX1', b'UPX!'],
            'ASPack': [b'aPLib'],
            'PECompact': [b'PECompact'],
            'Themida': [b'Themida'],
            'VMProtect': [b'VMProtect']
        }
        
        with open(self.packed_file, 'rb') as f:
            data = f.read()
        
        detected_packers = []
        for packer, signatures in packer_signatures.items():
            for sig in signatures:
                if sig in data:
                    detected_packers.append(packer)
                    break
        
        return detected_packers
    
    def analyze_entropy_distribution(self):
        """Analyze entropy distribution across sections"""
        section_entropies = []
        
        for section in self.pe.sections:
            section_data = section.get_data()
            if len(section_data) > 0:
                # Calculate entropy
                byte_counts = Counter(section_data)
                entropy = 0
                for count in byte_counts.values():
                    probability = count / len(section_data)
                    entropy -= probability * math.log2(probability)
                
                section_entropies.append({
                    'name': section.Name.decode().rstrip('\x00'),
                    'entropy': entropy,
                    'size': len(section_data),
                    'packed_likelihood': 'High' if entropy > 7.0 else 'Low'
                })
        
        return section_entropies
    
    def find_oep_candidates(self):
        """Find Original Entry Point candidates"""
        # Look for common unpacking stubs
        entry_point = self.pe.OPTIONAL_HEADER.AddressOfEntryPoint
        
        # Get code at entry point
        ep_data = self.pe.get_data(entry_point, 100)
        
        # Common unpacking patterns
        unpacking_patterns = [
            b'\x60\x8B\xEC',  # PUSHAD; MOV EBP, ESP
            b'\x55\x8B\xEC',  # PUSH EBP; MOV EBP, ESP
            b'\x53\x56\x57',  # PUSH EBX; PUSH ESI; PUSH EDI
        ]
        
        candidates = []
        for i, pattern in enumerate(unpacking_patterns):
            if pattern in ep_data:
                candidates.append({
                    'pattern': pattern.hex(),
                    'description': f'Unpacking pattern {i+1}',
                    'offset': ep_data.find(pattern)
                })
        
        return candidates
    
    def extract_embedded_pe(self):
        """Extract embedded PE files"""
        with open(self.packed_file, 'rb') as f:
            data = f.read()
        
        # Look for PE signatures
        pe_signatures = [b'MZ', b'PE\x00\x00']
        embedded_pes = []
        
        for sig in pe_signatures:
            offset = 0
            while True:
                offset = data.find(sig, offset + 1)
                if offset == -1:
                    break
                
                # Verify if it's a valid PE
                try:
                    if sig == b'MZ':
                        # Check for PE signature
                        pe_offset = struct.unpack('<L', data[offset+60:offset+64])[0]
                        if data[offset+pe_offset:offset+pe_offset+4] == b'PE\x00\x00':
                            embedded_pes.append({
                                'offset': offset,
                                'type': 'PE file',
                                'size_estimate': 'Unknown'
                            })
                except:
                    continue
        
        return embedded_pes

class MemoryForensicsAnalyzer:
    """Memory forensics analysis with Volatility"""
    
    def __init__(self, memory_dump_path):
        self.memory_dump = memory_dump_path
        self.volatility_path = "vol.py"  # Adjust path as needed
        
    def run_volatility_command(self, plugin, additional_args=""):
        """Run Volatility command and return output"""
        cmd = f"{self.volatility_path} -f {self.memory_dump} {plugin} {additional_args}"
        
        try:
            result = subprocess.run(
                cmd.split(),
                capture_output=True,
                text=True,
                timeout=300
            )
            return result.stdout
        except subprocess.TimeoutExpired:
            return "Command timed out"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def analyze_processes(self):
        """Analyze running processes"""
        print("[+] Analyzing processes...")
        
        # Get process list
        pslist_output = self.run_volatility_command("windows.pslist")
        
        # Get process tree
        pstree_output = self.run_volatility_command("windows.pstree")
        
        # Find hidden processes
        psxview_output = self.run_volatility_command("windows.psxview")
        
        return {
            'process_list': pslist_output,
            'process_tree': pstree_output,
            'hidden_processes': psxview_output
        }
    
    def analyze_network_connections(self):
        """Analyze network connections"""
        print("[+] Analyzing network connections...")
        
        # Network connections
        netscan_output = self.run_volatility_command("windows.netscan")
        
        # Network statistics
        netstat_output = self.run_volatility_command("windows.netstat")
        
        return {
            'network_scan': netscan_output,
            'network_stats': netstat_output
        }
    
    def find_malware_artifacts(self):
        """Find malware artifacts in memory"""
        print("[+] Searching for malware artifacts...")
        
        # Malware detection
        malfind_output = self.run_volatility_command("windows.malfind")
        
        # Suspicious processes
        hollowfind_output = self.run_volatility_command("windows.hollowfind")
        
        # Injected code
        ldrmodules_output = self.run_volatility_command("windows.ldrmodules")
        
        return {
            'malfind': malfind_output,
            'hollow_processes': hollowfind_output,
            'module_anomalies': ldrmodules_output
        }
    
    def comprehensive_analysis(self):
        """Run comprehensive memory analysis"""
        analysis_results = {
            'memory_dump': self.memory_dump,
            'processes': self.analyze_processes(),
            'network': self.analyze_network_connections(),
            'malware_artifacts': self.find_malware_artifacts()
        }
        
        return analysis_results

class MalwareClassifier:
    """Automated malware classification system"""
    
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.vectorizer = TfidfVectorizer(max_features=1000)
        self.feature_names = []
        self.is_trained = False
        
    def extract_features(self, file_path):
        """Extract features from malware sample"""
        features = {}
        
        try:
            # File-based features
            with open(file_path, 'rb') as f:
                data = f.read()
            
            features['file_size'] = len(data)
            features['entropy'] = self.calculate_entropy(data)
            
            # PE-specific features
            if self.is_pe_file(file_path):
                pe_features = self.extract_pe_features(file_path)
                features.update(pe_features)
            
            # String features
            string_features = self.extract_string_features(data)
            features.update(string_features)
            
            # Byte histogram features
            byte_features = self.extract_byte_histogram(data)
            features.update(byte_features)
            
        except Exception as e:
            print(f"Error extracting features from {file_path}: {e}")
            return None
        
        return features
    
    def calculate_entropy(self, data):
        """Calculate Shannon entropy"""
        if len(data) == 0:
            return 0
        
        byte_counts = Counter(data)
        entropy = 0
        
        for count in byte_counts.values():
            probability = count / len(data)
            entropy -= probability * math.log2(probability)
        
        return entropy
    
    def is_pe_file(self, file_path):
        """Check if file is PE format"""
        try:
            pefile.PE(file_path)
            return True
        except:
            return False
    
    def extract_pe_features(self, file_path):
        """Extract PE-specific features"""
        features = {}
        
        try:
            pe = pefile.PE(file_path)
            
            # Header features
            features['pe_machine'] = pe.FILE_HEADER.Machine
            features['pe_sections'] = len(pe.sections)
            features['pe_timestamp'] = pe.FILE_HEADER.TimeDateStamp
            features['pe_characteristics'] = pe.FILE_HEADER.Characteristics
            
            # Optional header features
            features['pe_entry_point'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
            features['pe_image_base'] = pe.OPTIONAL_HEADER.ImageBase
            features['pe_size_of_image'] = pe.OPTIONAL_HEADER.SizeOfImage
            
            # Section features
            executable_sections = 0
            writable_sections = 0
            total_entropy = 0
            
            for section in pe.sections:
                if section.Characteristics & 0x20000000:  # IMAGE_SCN_MEM_EXECUTE
                    executable_sections += 1
                if section.Characteristics & 0x80000000:  # IMAGE_SCN_MEM_WRITE
                    writable_sections += 1
                total_entropy += section.get_entropy()
            
            features['pe_executable_sections'] = executable_sections
            features['pe_writable_sections'] = writable_sections
            features['pe_avg_section_entropy'] = total_entropy / len(pe.sections)
            
            # Import features
            import_count = 0
            dll_count = 0
            
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                dll_count = len(pe.DIRECTORY_ENTRY_IMPORT)
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    import_count += len(entry.imports)
            
            features['pe_import_count'] = import_count
            features['pe_dll_count'] = dll_count
            
        except Exception as e:
            print(f"Error extracting PE features: {e}")
        
        return features
    
    def extract_string_features(self, data):
        """Extract string-based features"""
        features = {}
        
        # Extract strings
        ascii_strings = re.findall(b'[\x20-\x7E]{4,}', data)
        unicode_strings = re.findall(b'(?:[\x20-\x7E]\x00){4,}', data)
        
        features['string_count_ascii'] = len(ascii_strings)
        features['string_count_unicode'] = len(unicode_strings)
        
        # Specific pattern counts
        all_strings = b' '.join(ascii_strings + unicode_strings)
        
        features['url_count'] = len(re.findall(b'https?://', all_strings))
        features['ip_count'] = len(re.findall(b'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', all_strings))
        features['email_count'] = len(re.findall(b'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', all_strings))
        features['registry_count'] = len(re.findall(b'HKEY_', all_strings))
        features['file_path_count'] = len(re.findall(b'[A-Za-z]:\\\\', all_strings))
        
        return features
    
    def extract_byte_histogram(self, data, bins=256):
        """Extract byte frequency histogram features"""
        features = {}
        
        # Calculate byte frequency
        byte_counts = [0] * bins
        for byte in data:
            byte_counts[byte] += 1
        
        # Normalize
        total_bytes = len(data)
        if total_bytes > 0:
            byte_frequencies = [count / total_bytes for count in byte_counts]
        else:
            byte_frequencies = [0] * bins
        
        # Add as features
        for i, freq in enumerate(byte_frequencies):
            features[f'byte_freq_{i}'] = freq
        
        return features
    
    def classify_sample(self, file_path):
        """Classify a malware sample"""
        if not self.is_trained:
            raise ValueError("Model not trained yet")
        
        # Extract features
        features = self.extract_features(file_path)
        if not features:
            return None
        
        # Convert to DataFrame
        import pandas as pd
        df = pd.DataFrame([features])
        
        # Ensure all required features are present
        for feature_name in self.feature_names:
            if feature_name not in df.columns:
                df[feature_name] = 0
        
        # Select only training features
        X = df[self.feature_names].fillna(0)
        
        # Predict
        prediction = self.model.predict(X)[0]
        probabilities = self.model.predict_proba(X)[0]
        
        # Get class names
        classes = self.model.classes_
        
        # Create result
        result = {
            'prediction': prediction,
            'confidence': max(probabilities),
            'probabilities': dict(zip(classes, probabilities))
        }
        
        return result
    
    def save_model(self, model_path):
        """Save trained model"""
        model_data = {
            'model': self.model,
            'feature_names': self.feature_names,
            'is_trained': self.is_trained
        }
        joblib.dump(model_data, model_path)
        print(f"[+] Model saved to: {model_path}")
    
    def load_model(self, model_path):
        """Load trained model"""
        model_data = joblib.load(model_path)
        self.model = model_data['model']
        self.feature_names = model_data['feature_names']
        self.is_trained = model_data['is_trained']
        print(f"[+] Model loaded from: {model_path}")

# Usage examples
if __name__ == "__main__":
    # Static analysis example
    print("=== Static Analysis Example ===")
    static_analyzer = StaticAnalyzer("/path/to/malware.exe")
    basic_info = static_analyzer.get_basic_info()
    pe_info = static_analyzer.analyze_pe_structure()
    strings_info = static_analyzer.extract_strings()
    
    print(f"File size: {basic_info['file_size']} bytes")
    print(f"MD5: {basic_info['md5']}")
    print(f"SHA256: {basic_info['sha256']}")
    
    # Advanced analysis example
    print("\n=== Advanced Analysis Example ===")
    analyzer = AdvancedMalwareAnalyzer("/path/to/malware.exe")
    results = analyzer.generate_comprehensive_report()
    analyzer.save_report("comprehensive_malware_report.json")
    
    print(f"Risk Level: {results['risk_assessment']['level']}")
    print(f"Risk Score: {results['risk_assessment']['score']}")
    
    # Packed malware analysis example
    print("\n=== Packed Malware Analysis Example ===")
    packed_analyzer = PackedMalwareAnalyzer("/path/to/packed_malware.exe")
    packers = packed_analyzer.detect_packer()
    entropy = packed_analyzer.analyze_entropy_distribution()
    oep_candidates = packed_analyzer.find_oep_candidates()
    embedded = packed_analyzer.extract_embedded_pe()
    
    print(f"Detected packers: {packers}")
    print(f"High entropy sections: {[s['name'] for s in entropy if s['entropy'] > 7.0]}")
    
    # Memory forensics example
    print("\n=== Memory Forensics Example ===")
    memory_analyzer = MemoryForensicsAnalyzer("/path/to/memory.dump")
    memory_results = memory_analyzer.comprehensive_analysis()
    
    # Malware classification example
    print("\n=== Malware Classification Example ===")
    classifier = MalwareClassifier()
    
    # Load pre-trained model (if available)
    # classifier.load_model("malware_classifier.pkl")
    
    # Classify a sample
    # result = classifier.classify_sample("/path/to/unknown_sample.exe")
    # print(f"Classification: {result['prediction']} (confidence: {result['confidence']:.2f})")